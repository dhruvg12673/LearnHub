INSTRUCTIONS.md - EduAIthon 2026: "The Digital Twin Tutor"
1. Project Manifesto
Objective: Build an adaptive, personalized learning platform where a "Digital Twin" of the student negotiates with content agents to tailor the learning experience. Hackathon  Must be "Vacuum Proof" ( hallucination-resistant) but architecturally sophisticated.


Target Syllabus: Communication Engineering or any STEM based topic


2. High-Level Architecture (Multi-Agent System)
The system uses a Hub-and-Spoke architecture orchestrated by LangGraph. It is not a linear chain. It is a cyclic state machine.

The Agents (Nodes)
Planner Agent (The Architect):

Trigger: User states a topic (e.g., "Teach me Pulse Modulation").

Input: PDF Syllabus Content + User Request.

Output: A hierarchical JSON tree (Nodes/Edges) representing the dependency map of concepts.

Constraint: Must align with standard engineering progression (e.g., Sampling -> Quantization -> Encoding).

Digital Twin Agent (The Manager):

Role: State Manager & Negotiator.

Input: User ID, Current Topic.

Action: Fetches knowledge_state from Supabase.

Logic:

IF score < 40: Instruct Interface Agent to use "Story Mode" + Remedial Analogies.

IF score > 80: Instruct Interface Agent to use "Deep Dive" + Skip Basics.

IF last_quiz_failed: Trigger "Review Mode" before unlocking new content.

RAG Manager (The Librarian):

Role: Strict Content Retrieval.

Tools:

retrieve_syllabus(): FAISS Vector search on the uploaded PDF.

fetch_visuals(): Lookup curated Image IDs (Vacuum Proof) or Serper API (YouTube).

Constraint: Only retrieves content; does not generate explanations.

Interface Agent (The Face):

Role: Persona-based Content Generation.

Modes:

Story Mode: "Explain like I'm 5" / Analogies.

Deep Knowledge: Mathematical rigor, derivations, formal definitions.

Exam Mode: Rapid-fire facts, interview questions.

Input: Context (from RAG) + Instructions (from Twin).

Quiz & Evaluator Agent:

Role: Assessment & Feedback.

Action: Generates quizzes dynamically based on the specific content just taught.

Output: Score + Detailed Feedback Report (Weakness analysis, not just "5/10").

3. Tech Stack & Infrastructure
Frontend: React (Vite) + react-flow-renderer (Roadmap) + Axios.

Backend: Python (FastAPI).

Orchestration: LangGraph (StateGraph).

Inference: Ollama (Llama 3 / Mistral) running locally.

Memory (Vector): FAISS (Local file storage).

Memory (Relational): Supabase (PostgreSQL).

Connection: Connection Pooler (Port 6543) for IPv4 compatibility.

4. Data Structures
A. The Shared State (LangGraph)
The packet of data passed between agents:

Python

class AgentState(TypedDict):
    user_id: str
    request: str
    
    # Roadmap State
    roadmap_json: dict      # Generated by Planner
    current_node_id: str    # Which node user is clicking
    
    # Twin State
    mastery_score: int      # 0-100
    learning_style: str     # "visual", "theoretical"
    difficulty: str         # "easy", "hard"
    
    # Content State
    retrieved_docs: str
    video_assets: list
    
    # Output
    final_response: str
    next_action: str        # "render_map", "quiz", "content"
B. Database Schema (Supabase)
Table: knowledge_state | Column | Type | Purpose | | :--- | :--- | :--- | | user_id | TEXT | Linked to Frontend User | | subtopic_id | TEXT | Matches JSON Node ID (e.g., "sampling_theorem") | | mastery_score | INT | 0-100 | | weak_points | TEXT | Summary of what they failed (for feedback) | | last_accessed | TIME | For spaced repetition logic |

5. Functional Requirements (The "Vacuum Proof" MVP)
Feature 1: The Dynamic Roadmap
Do not hardcode nodes in React.

Flow:

User enters "Communication Engineering Module 2".

Planner Agent reads PDF -> Generates JSON.

Frontend receives JSON -> Renders ReactFlow graph.

Frontend queries Supabase -> Colors nodes (Green/Blue/Grey).

Feature 2: The Adaptive Chat Loop
Scenario: User clicks "Quantization" (Blue Node).

Flow:

Digital Twin checks Supabase: "User failed this last time."

Digital Twin sets mode="remedial".

RAG Agent fetches "Quantization basics" + img_quantization_error.png.

Interface Agent explains using a "Staircase Analogy" (because of remedial mode).

Feature 3: The Assessment Loop
Scenario: User clicks "Take Quiz".

Flow:

Frontend presents 3 questions (Hardcoded for MVP stability, or RAG-generated if robust).

User submits.

Backend calculates score.

CRITICAL: Backend writes to Supabase.

Backend returns feedback_report: "You understood Step Size, but failed Quantization Error."

Frontend turns Node Green.

6. Implementation Steps for LLM
Database & Auth: Ensure Supabase connection uses the Transaction Pooler (Port 6543) to avoid IPv4 errors.

RAG Ingestion: Run ingest.py targeting strictly Module 2 keywords to keep the vector index clean.

Graph Construction:

Build planner_node first (JSON generator).

Build digital_twin_node (Supabase read/write).

Connect them in workflow.py.

Frontend Integration:

Roadmap.jsx must accept nodes and edges as props from the API, not constants.

QuizModal.jsx must trigger a roadmap refresh upon closure.

7. Known "Gotchas" to Avoid
Hallucination: Do not let the Interface Agent invent YouTube links. Use the search_youtube tool or the hardcoded fallback list.

Graph Loops: Ensure the LangGraph has a definite END state so it doesn't loop infinitely between "Remedial" and "Quiz".

React Flow Height: Always wrap the <ReactFlow> component in a div with a fixed height (e.g., 80vh) or it will disappear.